{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing\n",
    "## Solinfitec Solix - PlantVillage Pipeline\n",
    "\n",
    "**Tasks**:\n",
    "- Scan for duplicate images\n",
    "- Detect corrupted images\n",
    "- Verify stratified split integrity\n",
    "- Preview augmentation pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from src.data.preprocessing import DataPreprocessor\n",
    "from src.data.dataset import PlantVillageDataset\n",
    "from src.features.augmentation import get_train_transforms, get_val_transforms\n",
    "\n",
    "DATA_DIR = Path('../../data/raw')\n",
    "PLANTVILLAGE_DIR = DATA_DIR / 'PlantVillage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Duplicate Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(str(DATA_DIR), skip_nested='PlantVillage/PlantVillage')\n",
    "\n",
    "print('Scanning for duplicates (by MD5 hash)...')\n",
    "duplicates = preprocessor.scan_duplicates()\n",
    "\n",
    "if duplicates:\n",
    "    total_dupes = sum(len(v) - 1 for v in duplicates.values())\n",
    "    print(f'Found {total_dupes} duplicate images in {len(duplicates)} groups')\n",
    "    # Show first 3 duplicate groups\n",
    "    for i, (h, files) in enumerate(list(duplicates.items())[:3]):\n",
    "        print(f'\\nGroup {i+1} ({len(files)} files):')\n",
    "        for f in files:\n",
    "            print(f'  {f}')\n",
    "else:\n",
    "    print('No duplicates found within top-level class directories.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Corrupted Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning for corrupted images...')\n",
    "corrupted = preprocessor.detect_corrupted()\n",
    "\n",
    "if corrupted:\n",
    "    print(f'Found {len(corrupted)} corrupted images:')\n",
    "    for c in corrupted[:10]:\n",
    "        print(f'  {c}')\n",
    "else:\n",
    "    print('All images are valid.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Stratified Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlantVillageDataset(str(PLANTVILLAGE_DIR), split='train', seed=42)\n",
    "val_ds = PlantVillageDataset(str(PLANTVILLAGE_DIR), split='val', seed=42)\n",
    "test_ds = PlantVillageDataset(str(PLANTVILLAGE_DIR), split='test', seed=42)\n",
    "\n",
    "print(f'Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}')\n",
    "print(f'Total: {len(train_ds) + len(val_ds) + len(test_ds)}')\n",
    "\n",
    "# Verify no overlap\n",
    "train_paths = set(train_ds.image_paths)\n",
    "val_paths = set(val_ds.image_paths)\n",
    "test_paths = set(test_ds.image_paths)\n",
    "assert len(train_paths & val_paths) == 0, 'Train/Val overlap!'\n",
    "assert len(train_paths & test_paths) == 0, 'Train/Test overlap!'\n",
    "assert len(val_paths & test_paths) == 0, 'Val/Test overlap!'\n",
    "print('No overlap between splits.')\n",
    "\n",
    "# Class distribution per split\n",
    "print('\\nTrain class counts:')\n",
    "for name, count in sorted(train_ds.get_label_counts().items()):\n",
    "    print(f'  {name}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Augmentation Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview training augmentations on a sample image\n",
    "sample_path = train_ds.image_paths[0]\n",
    "img = np.array(Image.open(sample_path).convert('RGB'))\n",
    "transform = get_train_transforms(img_size=224)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes[0, 0].imshow(img)\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    row, col = divmod(i, 4)\n",
    "    augmented = transform(image=img)['image']\n",
    "    # Denormalize for display\n",
    "    display = augmented.permute(1, 2, 0).numpy()\n",
    "    display = display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    display = np.clip(display, 0, 1)\n",
    "    axes[row, col].imshow(display)\n",
    "    axes[row, col].set_title(f'Aug #{i}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Training Augmentation Samples', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
