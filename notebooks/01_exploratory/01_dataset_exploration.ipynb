{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Dataset Exploration - PlantVillage\n## Solinfitec Solix - Disease Detection System\n\n**Objective**: Exploratory analysis of the PlantVillage dataset (15 classes, ~20K images)\n\n**Key Questions**:\n- Class distribution and imbalance\n- Image dimensions and quality\n- Channel statistics for normalization\n- Identify minority classes needing augmentation boost"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '../..')\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\nfrom collections import Counter\n\nfrom src.data.preprocessing import DataPreprocessor\nfrom src.visualization.dataset_plots import plot_class_distribution, plot_sample_grid, plot_image_size_distribution\n\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nDATA_DIR = Path('../../data/raw')\nprint(f\"Data directory: {DATA_DIR.resolve()}\")\nprint(f\"Exists: {DATA_DIR.exists()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregar Paths dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize preprocessor\npreprocessor = DataPreprocessor(str(DATA_DIR), skip_nested=\"PlantVillage/PlantVillage\")\n\n# Get valid class directories (skipping nested duplicate)\nclass_dirs = preprocessor.get_valid_class_dirs()\nprint(f\"Found {len(class_dirs)} valid classes:\")\nfor d in class_dirs:\n    print(f\"  - {d.name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise de Distribuição de Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Class distribution\nclass_counts = preprocessor.get_class_counts()\ntotal = sum(class_counts.values())\nprint(f\"Total images: {total}\")\nprint(f\"\\nClass distribution:\")\nfor name, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):\n    pct = count / total * 100\n    print(f\"  {name}: {count} ({pct:.1f}%)\")\n\n# Imbalance ratio\nmax_count = max(class_counts.values())\nmin_count = min(class_counts.values())\nprint(f\"\\nImbalance ratio: {max_count/min_count:.1f}x\")\nprint(f\"Largest class: {max(class_counts, key=class_counts.get)} ({max_count})\")\nprint(f\"Smallest class: {min(class_counts, key=class_counts.get)} ({min_count})\")\n\n# Plot\nplot_class_distribution(class_counts, title=\"PlantVillage Class Distribution\",\n                       save_path=\"../../reports/class_distribution.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualização de Amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Sample images from each class\nimport random\nrandom.seed(42)\n\nfig, axes = plt.subplots(3, 5, figsize=(18, 12))\naxes = axes.flatten()\n\nfor i, class_dir in enumerate(class_dirs[:15]):\n    images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.JPG\"))\n    if images:\n        sample = random.choice(images)\n        img = Image.open(sample).convert(\"RGB\")\n        axes[i].imshow(img)\n        axes[i].set_title(class_dir.name.replace(\"_\", \"\\n\"), fontsize=7)\n    axes[i].axis(\"off\")\n\nplt.suptitle(\"Sample Images per Class\", fontsize=14)\nplt.tight_layout()\nplt.savefig(\"../../reports/sample_images.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise de Dimensões das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Image size distribution\nsizes = preprocessor.get_image_sizes(sample_size=500)\nwidths = [s[0] for s in sizes]\nheights = [s[1] for s in sizes]\n\nprint(f\"Width  - mean: {np.mean(widths):.0f}, std: {np.std(widths):.0f}, \"\n      f\"range: [{min(widths)}, {max(widths)}]\")\nprint(f\"Height - mean: {np.mean(heights):.0f}, std: {np.std(heights):.0f}, \"\n      f\"range: [{min(heights)}, {max(heights)}]\")\n\n# Aspect ratios\naspects = [w/h for w, h in sizes]\nprint(f\"Aspect ratio - mean: {np.mean(aspects):.3f}, std: {np.std(aspects):.3f}\")\n\nplot_image_size_distribution(sizes, save_path=\"../../reports/image_sizes.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise de Canais de Cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Channel statistics (for normalization)\nprint(\"Computing channel mean/std (this may take a minute)...\")\nmean, std = preprocessor.compute_channel_stats(sample_size=2000)\n\nprint(f\"\\nChannel Mean: {mean}\")\nprint(f\"Channel Std:  {std}\")\nprint(f\"\\nImageNet default: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\")\n\n# Minority classes identification\nfrom src.features.augmentation import get_minority_classes\nminorities = get_minority_classes(class_counts, threshold=500)\nprint(f\"\\nMinority classes (<500 samples): {minorities}\")\nprint(f\"These will receive 3x augmentation boost during training.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conclusions\n\n### Key Findings:\n- **15 classes** (3 crops: Pepper, Potato, Tomato with diseases and healthy variants)\n- **High class imbalance**: Tomato_YellowLeaf_Curl_Virus (~3200) vs Potato_healthy (~150)\n- **Minority classes** (<500): Potato_healthy, Tomato_mosaic_virus need augmentation boost\n- **Images**: Mostly 256x256 RGB, suitable for 224x224 Swin input\n\n### Strategy:\n- WeightedRandomSampler for balanced training batches\n- 3x augmentation multiplier for minority classes\n- FocalLoss with per-class alpha weights\n- Stratified train/val/test split (70/15/15)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}