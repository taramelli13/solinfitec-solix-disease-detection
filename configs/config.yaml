# Solinfitec Solix - Disease Detection & Outbreak Prediction
# Architecture: Swin Transformer + Temporal Transformer + Multi-Modal Fusion

# ============================================================================
# Data Configuration
# ============================================================================
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  external_dir: "data/external"
  dataset_name: "PlantVillage"
  img_size: [224, 224]
  batch_size: 32
  num_workers: 0
  train_split: 0.70
  val_split: 0.15
  test_split: 0.15
  pin_memory: true
  # Nested duplicate directory to skip during loading
  skip_nested: "PlantVillage/PlantVillage"
  # Channel normalization (ImageNet defaults, recalculated during preprocessing)
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# ============================================================================
# Swin Transformer (Visual Backbone)
# ============================================================================
model:
  architecture: "swin_transformer"
  variant: "swin_tiny_patch4_window7_224"
  pretrained: true
  num_classes: 15  # 15 PlantVillage top-level classes
  feature_dim: 768
  head:
    hidden_dim: 256
    dropout: 0.3
    activation: "gelu"
  # Freeze strategy for training
  freeze:
    stages_frozen: [0, 1]  # Frozen during initial epochs
    unfreeze_epoch: 10

# ============================================================================
# Temporal Transformer (IoT/Weather Encoder)
# ============================================================================
temporal_model:
  d_model: 128
  nhead: 8
  num_layers: 4
  dim_feedforward: 512
  dropout: 0.1
  sequence_length: 30  # 30 days lookback
  num_features: 7  # temp, humidity, soil_moisture, wind, rain, disease_prev, gdd
  output_dim: 256

# ============================================================================
# Spatial MLP (Geo/GPS Encoder)
# ============================================================================
spatial_model:
  input_dim: 3  # lat, lon, elevation
  hidden_dim: 64
  output_dim: 128

# ============================================================================
# Multi-Modal Fusion
# ============================================================================
fusion:
  visual_proj_dim: 256
  temporal_dim: 256
  spatial_dim: 128
  fused_dim: 640
  cross_attention:
    nhead: 8
    dropout: 0.1
  gated_fusion: true

# ============================================================================
# Prediction Heads
# ============================================================================
prediction_heads:
  disease_classification:
    input_dim: 640
    num_classes: 15
  outbreak_regression:
    input_dim: 640
    forecast_days: 7
  severity:
    input_dim: 640
    num_levels: 4  # healthy, initial, moderate, severe

# ============================================================================
# Training - Swin Classifier (Phase 2)
# ============================================================================
training:
  # Phase 1: Frozen stages
  epochs: 50
  learning_rate: 1.0e-4
  optimizer: "AdamW"
  weight_decay: 0.05
  scheduler: "CosineAnnealingWarmRestarts"
  scheduler_params:
    T_0: 10
    T_mult: 2
    eta_min: 1.0e-6
  # Phase 2: Unfreezing
  unfreeze_epoch: 10
  lr_reduction_factor: 0.1  # lr *= 0.1 at unfreeze
  # Early stopping
  early_stopping:
    patience: 10
    monitor: "val_f1"
    mode: "max"
  # Gradient
  grad_clip_norm: 1.0
  # Loss
  loss: "focal"
  focal_gamma: 2.0

# ============================================================================
# Training - Fusion Model (Phase 4)
# ============================================================================
fusion_training:
  epochs: 80
  learning_rate: 3.0e-4
  optimizer: "AdamW"
  weight_decay: 0.01
  scheduler: "CosineAnnealingWarmRestarts"
  scheduler_params:
    T_0: 15
    T_mult: 2
    eta_min: 1.0e-6
  freeze_swin_backbone: true
  early_stopping:
    patience: 15
    monitor: "val_total_loss"
    mode: "min"
  # Multi-task loss weights (learned via uncertainty)
  multitask_loss:
    method: "uncertainty"  # Kendall et al. 2018

# ============================================================================
# Augmentation
# ============================================================================
augmentation:
  train:
    random_resized_crop:
      size: 224
      scale: [0.7, 1.0]
    horizontal_flip: 0.5
    vertical_flip: 0.2
    color_jitter:
      brightness: 0.3
      contrast: 0.3
      saturation: 0.3
      hue: 0.1
    gaussian_noise:
      var_limit: [10, 50]
      p: 0.3
    coarse_dropout:
      max_holes: 8
      max_height: 32
      max_width: 32
      p: 0.3
    mixup:
      enabled: true
      alpha: 0.2
    cutmix:
      enabled: true
      alpha: 1.0
  # Minority class extra augmentation
  minority_threshold: 500
  minority_multiplier: 3
  # Validation/Test
  val:
    resize: 256
    center_crop: 224

# ============================================================================
# IoT Simulation
# ============================================================================
iot_simulation:
  num_fields: 50
  days: 365
  seed: 42
  output_dir: "data/processed/iot_simulated"
  temperature:
    base_mean: 25.0
    base_amplitude: 8.0
    diurnal_amplitude: 5.0
    ar1_coeff: 0.7
    noise_std: 1.5
  humidity:
    base_mean: 70.0
    anti_corr_factor: -1.5
    noise_std: 5.0
  soil_moisture:
    initial: 0.35
    rain_factor: 0.05
    decay_rate: 0.03
  wind:
    log_mean: 1.5
    log_std: 0.6
  rain:
    zero_inflation: 0.7
    gamma_shape: 0.8
    gamma_scale: 5.0
  disease_seir:
    S0: 0.95
    E0: 0.03
    I0: 0.02
    R0: 0.0
    beta_base: 0.3
    sigma: 0.1
    gamma: 0.05
    temp_optimal: 25.0
    humidity_optimal: 85.0

# ============================================================================
# Weather API
# ============================================================================
weather:
  api: "open-meteo"
  base_url: "https://api.open-meteo.com/v1/forecast"
  cache_dir: "data/external/weather_cache"
  fallback_to_simulation: true

# ============================================================================
# Alert System
# ============================================================================
alerts:
  risk_thresholds:
    low: 0.2
    medium: 0.5
    high: 0.75
    critical: 0.9
  severity_labels: ["healthy", "initial", "moderate", "severe"]
  actions:
    low: "Continue regular monitoring."
    medium: "Increase inspection frequency. Consider preventive treatment."
    high: "Apply targeted treatment immediately. Isolate affected area."
    critical: "Emergency intervention required. Full field treatment recommended."

# ============================================================================
# Evaluation
# ============================================================================
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1", "auroc", "mAP@0.5"]
  per_class: true
  confusion_matrix: true
  grad_cam:
    enabled: true
    target_layer: "stage3"  # Swin Stage 3
  num_visualization_samples: 50

# ============================================================================
# Export (Edge Deployment)
# ============================================================================
export:
  format: "onnx"
  opset_version: 14
  quantization:
    enabled: false
    type: "fp16"  # Options: int8, fp16
  target_device: "jetson_xavier"
  validate_output: true
  max_diff: 1.0e-5
  benchmark_latency: true
  output_dir: "models/final"

# ============================================================================
# MQTT Interface
# ============================================================================
mqtt:
  broker_host: "localhost"
  broker_port: 1883
  topics:
    sensor_data: "solix/sensors/{field_id}"
    alerts: "solix/alerts/{field_id}"
    predictions: "solix/predictions/{field_id}"
  qos: 1

# ============================================================================
# Logging & Paths
# ============================================================================
logging:
  level: "INFO"
  log_file: "logs/training.log"
  use_tensorboard: true
  tensorboard_dir: "logs/tensorboard"

paths:
  checkpoint_dir: "models/checkpoints"
  final_model_dir: "models/final"
  log_dir: "logs"
  report_dir: "reports"
  metrics_dir: "reports/metrics"

# ============================================================================
# MLflow
# ============================================================================
mlflow:
  tracking_uri: "file:./mlruns"
  experiment_classifier: "swin_classifier"
  experiment_fusion: "fusion_multimodal"
  registered_model_classifier: "SwinClassifier"
  registered_model_fusion: "MultiModalFusion"

# ============================================================================
# Reproducibility
# ============================================================================
seed: 42
