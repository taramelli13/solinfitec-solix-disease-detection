# DiaMOS Plant Dataset - Fusion Training Configuration
# Trains severity head with real severity labels from DiaMOS (pear leaves)
# Disease classes: healthy, spot, curl, slug (4 classes)

# ============================================================================
# Data Configuration
# ============================================================================
data:
  raw_dir: "data"
  processed_dir: "data/processed"
  external_dir: "data/external"
  dataset_name: "diamos"
  diamos_dir: "data/diamos"
  img_size: [224, 224]
  batch_size: 16
  num_workers: 0
  train_split: 0.70
  val_split: 0.15
  test_split: 0.15
  pin_memory: true
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# ============================================================================
# Swin Transformer (Visual Backbone) - same architecture
# ============================================================================
model:
  architecture: "swin_transformer"
  variant: "swin_tiny_patch4_window7_224"
  pretrained: true
  num_classes: 4  # DiaMOS: healthy, spot, curl, slug
  feature_dim: 768
  head:
    hidden_dim: 256
    dropout: 0.3
    activation: "gelu"
  freeze:
    stages_frozen: [0, 1]
    unfreeze_epoch: 10

# ============================================================================
# Temporal Transformer (IoT/Weather Encoder) - same as main config
# ============================================================================
temporal_model:
  d_model: 128
  nhead: 8
  num_layers: 4
  dim_feedforward: 512
  dropout: 0.1
  sequence_length: 30
  num_features: 7
  output_dim: 256

# ============================================================================
# Spatial MLP
# ============================================================================
spatial_model:
  input_dim: 3
  hidden_dim: 64
  output_dim: 128

# ============================================================================
# Multi-Modal Fusion
# ============================================================================
fusion:
  visual_proj_dim: 256
  temporal_dim: 256
  spatial_dim: 128
  fused_dim: 640
  cross_attention:
    nhead: 8
    dropout: 0.1
  gated_fusion: true

# ============================================================================
# Prediction Heads
# ============================================================================
prediction_heads:
  disease_classification:
    input_dim: 640
    num_classes: 4
  outbreak_regression:
    input_dim: 640
    forecast_days: 7
  severity:
    input_dim: 640
    num_levels: 4  # healthy, initial, moderate, severe

# ============================================================================
# Training - DiaMOS Fusion (smaller dataset, more conservative)
# ============================================================================
training:
  epochs: 50
  learning_rate: 1.0e-4
  optimizer: "AdamW"
  weight_decay: 0.05
  scheduler: "CosineAnnealingWarmRestarts"
  scheduler_params:
    T_0: 10
    T_mult: 2
    eta_min: 1.0e-6
  unfreeze_epoch: 10
  lr_reduction_factor: 0.1
  early_stopping:
    patience: 10
    monitor: "val_f1"
    mode: "max"
  grad_clip_norm: 1.0
  loss: "focal"
  focal_gamma: 2.0

fusion_training:
  epochs: 50
  learning_rate: 1.0e-4
  optimizer: "AdamW"
  weight_decay: 0.01
  scheduler: "CosineAnnealingWarmRestarts"
  scheduler_params:
    T_0: 10
    T_mult: 2
    eta_min: 1.0e-6
  freeze_swin_backbone: true
  early_stopping:
    patience: 15
    monitor: "val_total_loss"
    mode: "min"
  multitask_loss:
    method: "uncertainty"

# ============================================================================
# Augmentation (stronger for small dataset)
# ============================================================================
augmentation:
  train:
    random_resized_crop:
      size: 224
      scale: [0.6, 1.0]
    horizontal_flip: 0.5
    vertical_flip: 0.3
    color_jitter:
      brightness: 0.4
      contrast: 0.4
      saturation: 0.4
      hue: 0.15
    gaussian_noise:
      var_limit: [10, 50]
      p: 0.4
    coarse_dropout:
      max_holes: 8
      max_height: 32
      max_width: 32
      p: 0.4
    mixup:
      enabled: true
      alpha: 0.3
    cutmix:
      enabled: true
      alpha: 1.0
  minority_threshold: 200
  minority_multiplier: 4
  val:
    resize: 256
    center_crop: 224

# ============================================================================
# IoT Simulation (calibrated from Grape Disease Dataset)
# ============================================================================
iot_simulation:
  num_fields: 20
  days: 365
  seed: 42
  output_dir: "data/processed/iot_simulated_diamos"
  # Calibration source (optional, applied at runtime)
  calibration_csv: "data/grape_disease/Grape_Disease_Dataset.csv"
  temperature:
    base_mean: 25.0
    base_amplitude: 8.0
    diurnal_amplitude: 5.0
    ar1_coeff: 0.7
    noise_std: 1.5
  humidity:
    base_mean: 70.0
    anti_corr_factor: -1.5
    noise_std: 5.0
  soil_moisture:
    initial: 0.35
    rain_factor: 0.05
    decay_rate: 0.03
  wind:
    log_mean: 1.5
    log_std: 0.6
  rain:
    zero_inflation: 0.7
    gamma_shape: 0.8
    gamma_scale: 5.0
  disease_seir:
    S0: 0.95
    E0: 0.03
    I0: 0.02
    R0: 0.0
    beta_base: 0.3
    sigma: 0.1
    gamma: 0.05
    temp_optimal: 25.0
    humidity_optimal: 85.0

# ============================================================================
# Alert System
# ============================================================================
alerts:
  risk_thresholds:
    low: 0.2
    medium: 0.5
    high: 0.75
    critical: 0.9
  severity_labels: ["healthy", "initial", "moderate", "severe"]
  actions:
    low: "Continue regular monitoring."
    medium: "Increase inspection frequency. Consider preventive treatment."
    high: "Apply targeted treatment immediately. Isolate affected area."
    critical: "Emergency intervention required. Full field treatment recommended."

# ============================================================================
# Logging & Paths
# ============================================================================
logging:
  level: "INFO"
  log_file: "logs/training_diamos.log"
  use_tensorboard: true
  tensorboard_dir: "logs/tensorboard_diamos"

paths:
  checkpoint_dir: "models/checkpoints"
  final_model_dir: "models/final"
  log_dir: "logs"
  report_dir: "reports"
  metrics_dir: "reports/metrics"

seed: 42
